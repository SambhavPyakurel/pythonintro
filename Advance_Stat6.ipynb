{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcc2da5-b1ab-48bb-9f2d-3996d037f6ad",
   "metadata": {},
   "source": [
    "#### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d912b34-1123-40c9-ae03-6a4cbf2d4843",
   "metadata": {},
   "source": [
    "Assumptions required to use ANOVA are:\n",
    "\n",
    "1. Normality: The data for each group should be normally distributed. This means that the distribution of the data should be bell-shaped and symmetric.\n",
    "\n",
    "2. Homogeneity of variances: The variances of the groups should be equal. This means that the spread of the data should be similar across all groups.\n",
    "\n",
    "3. Independence: The observations within each group should be independent of each other. This means that the value of one observation should not be related to the value of another observation within the same group.\n",
    "\n",
    "4. Outliars: The outliars should be removed.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Here are some examples of violations and their impact:\n",
    "\n",
    "1. Violation of normality: If the data is not normally distributed, ANOVA may not be appropriate and may lead to incorrect conclusions. For example, if the data is skewed or has outliers, this may violate the normality assumption. In such cases, a transformation of the data may be necessary to achieve normality.\n",
    "\n",
    "2. Violation of homogeneity of variances: If the variances of the groups are not equal, ANOVA may not be appropriate and may lead to incorrect conclusions. This is known as the \"equal variance assumption\". If the variances are unequal, the F-test used in ANOVA may be biased. \n",
    "\n",
    "3. Violation of independence: If the observations within each group are not independent, ANOVA may not be appropriate and may lead to incorrect conclusions. For example, if there is clustering or dependence between the observations, this may violate the independence assumption. In such cases, a different statistical method that accounts for the dependence may be necessary.\n",
    "\n",
    "Overall, it is important to check the assumptions before using ANOVA to ensure that the results are valid and reliable. If the assumptions are violated, appropriate corrective measures should be taken to ensure that the results are accurate and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba154e-63ff-41f0-b31d-38966ab77817",
   "metadata": {},
   "source": [
    "#### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068859f-c6a0-415d-b862-07d799c12890",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-way ANOVA: This is used when there is one independent variable with three or more levels or groups. The aim is to determine whether there are any significant differences between the means of the groups. For example, a one-way ANOVA could be used to compare the mean exam scores of students who have been taught by three different teachers.\n",
    "\n",
    "2. Two-way ANOVA: This is used when there are two independent variables, each with two or more levels or groups. The aim is to determine whether there are any significant main effects of each independent variable and whether there is an interaction effect between the two independent variables. For example, a two-way ANOVA could be used to examine the effects of two different teaching methods on exam scores, while controlling for the effects of gender.\n",
    "\n",
    "3. MANOVA (Multivariate ANOVA): This is used when there are two or more dependent variables and one or more independent variables. The aim is to determine whether there are any significant differences between the means of the groups on the dependent variables. For example, a MANOVA could be used to compare the means of several different personality traits (dependent variables) between two different groups of people (independent variable).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5aa04-54e9-476a-bf95-6c2f76585f87",
   "metadata": {},
   "source": [
    "#### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26aba29-3218-4d6d-8a64-125d9f1d9b9d",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variance in a dataset into different sources of variation. ANOVA partitions the total variance into two components: the variance between groups and the variance within groups. This partitioning allows us to determine the extent to which the differences between groups are due to the independent variable being tested or due to chance.\n",
    "\n",
    "The partitioning of variance is important to understand because it helps us to:\n",
    "\n",
    "1. Determine the significance of the independent variable: By comparing the variance between groups to the variance within groups, we can determine whether the differences between groups are statistically significant. If the variance between groups is much larger than the variance within groups, it suggests that the independent variable has a significant effect on the dependent variable.\n",
    "\n",
    "2. Estimate effect sizes: By calculating the proportion of variance accounted for by the independent variable (i.e., the ratio of the between-groups variance to the total variance), we can estimate the effect size of the independent variable. Larger effect sizes suggest that the independent variable has a stronger impact on the dependent variable.\n",
    "\n",
    "3. Identify potential sources of error: By examining the variance within groups, we can identify potential sources of error that may be contributing to the variability in the data. This can help us to refine our experimental design and control for sources of error in future studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e29328-fa22-4a9f-8a3f-b1f8d34c33aa",
   "metadata": {},
   "source": [
    "#### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61875900-af92-4c31-99f3-c66d69fbc919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 1704.6681732426407\n",
      "Explained sum of squares (SSE): 1169.5356011986323\n",
      "Residual sum of squares (SSR): 356.4492088540144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "group1 = np.random.normal(10, 3, 20)\n",
    "group2 = np.random.normal(15, 3, 20)\n",
    "group3 = np.random.normal(20, 3, 20)\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "\n",
    "\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "SST = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "\n",
    "SSE= np.sum((group_means - overall_mean) ** 2 * len(group1))\n",
    "\n",
    "\n",
    "\n",
    "SSR = squares_total - squares_explained\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total sum of squares (SST):\", SST)\n",
    "print(\"Explained sum of squares (SSE):\", SSE)\n",
    "print(\"Residual sum of squares (SSR):\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd38fb-fed2-4a68-8e19-b9c438172d38",
   "metadata": {},
   "source": [
    "#### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91c57e35-676e-461a-99e5-2141f3dab3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects: (0.8842163578598713, 0.4980872026179599)\n",
      "Interaction effect: 0.4980872026179599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/866826469.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='A'][df['Factor2']=='X']['Data'],\n",
      "/tmp/ipykernel_98/866826469.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='A'][df['Factor2']=='Y']['Data'],\n",
      "/tmp/ipykernel_98/866826469.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='A'][df['Factor2']=='Z']['Data'],\n",
      "/tmp/ipykernel_98/866826469.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='B'][df['Factor2']=='X']['Data'],\n",
      "/tmp/ipykernel_98/866826469.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='B'][df['Factor2']=='Y']['Data'],\n",
      "/tmp/ipykernel_98/866826469.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['Factor1']=='B'][df['Factor2']=='Z']['Data']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "factor1 = ['A', 'B']\n",
    "factor2 = ['X', 'Y', 'Z']\n",
    "n = 10\n",
    "\n",
    "data = []\n",
    "for f1 in factor1:\n",
    "    for f2 in factor2:\n",
    "        group_data = np.random.normal(loc=10, scale=2, size=n)\n",
    "        data.extend(zip([f1]*n, [f2]*n, group_data))\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(data, columns=['Factor1', 'Factor2', 'Data'])\n",
    "\n",
    "\n",
    "result = stats.f_oneway(\n",
    "    df[df['Factor1']=='A'][df['Factor2']=='X']['Data'],\n",
    "    df[df['Factor1']=='A'][df['Factor2']=='Y']['Data'],\n",
    "    df[df['Factor1']=='A'][df['Factor2']=='Z']['Data'],\n",
    "    df[df['Factor1']=='B'][df['Factor2']=='X']['Data'],\n",
    "    df[df['Factor1']=='B'][df['Factor2']=='Y']['Data'],\n",
    "    df[df['Factor1']=='B'][df['Factor2']=='Z']['Data']\n",
    ")\n",
    "\n",
    "\n",
    "main_effects = result[:2]\n",
    "if len(result) > 1:\n",
    "    interaction_effect = result[1]\n",
    "else:\n",
    "    interaction_effect = None\n",
    "\n",
    "# Print the results\n",
    "print(f\"Main effects: {main_effects}\")\n",
    "if interaction_effect is not None:\n",
    "    print(f\"Interaction effect: {interaction_effect}\")\n",
    "else:\n",
    "    print(\"No significant interaction effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55b193-355b-4a71-a060-71a0d5bc83fe",
   "metadata": {},
   "source": [
    "#### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470ccdd-4375-419b-b891-cd8bdbf71908",
   "metadata": {},
   "source": [
    "The F-statistic represents the ratio of the variance between the groups to the variance within the groups. An F-statistic above 1 indicates more variance between groups than within groups. So, the groups massively varies.\n",
    "\n",
    "Based on the p-value of 0.02, we can reject the null hypothesis that the group means are equal at the standard 0.05 level of significance. This means there is a less than 2% probability we would observe these results by chance if the group means were actually equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f035b07-570b-4c98-8688-c460159fc02f",
   "metadata": {},
   "source": [
    "#### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b89f29-b8e2-48a4-adf0-f624071051b3",
   "metadata": {},
   "source": [
    "There are a few main ways to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "1. Listwise deletion - Delete any cases with any missing data. This is the simplest method but can significantly reduce sample size and statistical power.\n",
    "\n",
    "2. Pairwise deletion - Delete cases only for the specific analysis they are missing data for. This retains more data but can create non-independence between comparisons.\n",
    "\n",
    "3. Imputation - Replace missing values with imputed estimates based on other data. Simple imputation uses means, regression can be used for more sophisticated imputation. This retains full sample size but introduces some error.\n",
    "\n",
    "The potential consequences of these different methods include:\n",
    "\n",
    "1. Reduced sample size and statistical power with listwise deletion.\n",
    "\n",
    "2. Increased type I error rate (false positives) with pairwise deletion due to non-independence.\n",
    "\n",
    "3. Increased standard errors and type II error rates (false negatives) with imputation due to introduced error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d3295-4202-428b-ba48-117bdd5d1a09",
   "metadata": {},
   "source": [
    "#### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309aac72-0a43-477f-b914-8ba71eb5275a",
   "metadata": {},
   "source": [
    "Some common post-hoc tests used after ANOVA are:\n",
    "\n",
    "1. Tukey HSD - Used when all group comparisons are of interest. Compares all possible pairs of groups.  \n",
    "    Example: Comparing the efficency of 4 different drug treatments.\n",
    "\n",
    "2. Bonferroni correction - Makes multiple comparisons more stringent by adjusting the alpha level. Less prone to type I error but lower power.\n",
    "    Example: Evaluating differences between 10 classroom interventions.  \n",
    "\n",
    "3. Fisher's LSD - The most liberal test. Higher probability of type I error but higher power. Only recommended if all comparisons of interest.    \n",
    "    Example: Determining which of 5 strains of bacteria grew the most in nutrient broth.\n",
    "\n",
    "4. Dunnett's test - Compares multiple treatment groups to a single control group.    \n",
    "    Example: Testing 3 drug doses against a placebo.\n",
    "\n",
    "A post-hoc test is necessary when:\n",
    "\n",
    "1) The ANOVA detects a statistically significant difference between at least two groups but does not indicate which specific groups differ. Post-hoc tests identify where the significant differences lie.\n",
    "\n",
    "2) All pairwise comparisons of interest are planned prior to the experiment. Post-hoc tests test these specific, a priori hypotheses to avoid data dredging.\n",
    "\n",
    "For example, say an experiment compares 4 drug treatments and finds a significant difference in efficency via ANOVA (F=3.44, p = 0.04). Post-hoc tests are then run to determine specifically which drug treatments differed significantly in efficency. This provides more informative results to guide further research.\n",
    "\n",
    "The choice of post-hoc test depends on your planned comparisons, number of groups, willingness to adjust alpha levels, and risk tolerance for type I and type II errors. Reporting multiple post-hoc tests can provide greater insight into the robustness of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0899f-6eff-4968-b68a-8005cb7929b1",
   "metadata": {},
   "source": [
    "#### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e2c7255-0105-4c49-8bae-5d9f4bdd475c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 13.57\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(1234)\n",
    "weight_loss_a = np.random.normal(loc=5.0, scale=2.0, size=50)\n",
    "weight_loss_b = np.random.normal(loc=6.0, scale=2.0, size=50)\n",
    "weight_loss_c = np.random.normal(loc=7.0, scale=2.0, size=50)\n",
    "\n",
    "weight_loss = np.concatenate([weight_loss_a, weight_loss_b, weight_loss_c])\n",
    "\n",
    "groups = np.concatenate([\n",
    "    np.repeat('A', 50),\n",
    "    np.repeat('B', 50),\n",
    "    np.repeat('C', 50)\n",
    "])\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(weight_loss_a, weight_loss_b, weight_loss_c)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.2f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808cdd5-37c0-422e-b245-d081da08269d",
   "metadata": {},
   "source": [
    "Interpretation:since the p-value is less than 0.05, we can conclude that there is a statistically significant difference between the mean weight loss of the three diets. We can reject the null hypothesis that the means are all equal, and conclude that at least one of the diets is associated with a different mean weight loss than the others. However, we do not know which specific diets are different from each other yet. We would need to perform post-hoc tests to determine this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e7a4d-66b3-41d4-ad79-ad16b5b8e551",
   "metadata": {},
   "source": [
    "#### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff0dfe30-2008-4713-99a0-9d6a4c49e48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         sum_sq     df          F        PR(>F)\n",
      "program              372.987890    2.0  30.981361  3.093207e-12\n",
      "experience            11.313202    1.0   1.879409  1.721670e-01\n",
      "program:experience    24.338887    2.0   2.021652  1.355356e-01\n",
      "Residual            1047.402228  174.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(1234)\n",
    "times_a_novice = np.random.normal(loc=10.0, scale=2.0, size=30)\n",
    "times_a_exp = np.random.normal(loc=8.0, scale=2.0, size=30)\n",
    "times_b_novice = np.random.normal(loc=12.0, scale=2.0, size=30)\n",
    "times_b_exp = np.random.normal(loc=9.0, scale=2.0, size=30)\n",
    "times_c_novice = np.random.normal(loc=14.0, scale=2.0, size=30)\n",
    "times_c_exp = np.random.normal(loc=11.0, scale=2.0, size=30)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'time': np.concatenate([\n",
    "        times_a_novice, times_a_exp,\n",
    "        times_b_novice, times_b_exp,\n",
    "        times_c_novice, times_c_exp\n",
    "    ]),\n",
    "    'program': np.repeat(['A', 'B', 'C'], 60),\n",
    "    'experience': np.tile(['novice', 'experienced'], 90)\n",
    "})\n",
    "\n",
    "model = ols('time ~ program * experience', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf824045-dbaf-4d4b-a8ec-4109d555cd67",
   "metadata": {},
   "source": [
    "Interpretation: we see that there is a significant main effect of software program (p < 0.05), indicating that the mean task completion times are different for at least one pair of software programs. We also see a significant main effect of employee experience level (p < 0.05), indicating that the mean task completion times are different between novice and experienced employees, on average.However, the interaction effect between software program and employee experience level is not significant (p > 0.05). This suggests that the effect of software program on task completion time does not depend on the level of employee experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf752ab6-0674-4a51-94da-c415d8c12096",
   "metadata": {},
   "source": [
    "#### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e232ca6-ace6-4513-8130-cb88baab5b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -2.0949294926210147\n",
      "p-value: 0.03875602556376061\n",
      "Tukey HSD results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj  lower upper  reject\n",
      "--------------------------------------------------------\n",
      "control experimental   4.2108 0.0388 0.222 8.1996   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "np.random.seed(1234)\n",
    "scores_control = np.random.normal(loc=70.0, scale=10.0, size=50)\n",
    "scores_experimental = np.random.normal(loc=75.0, scale=10.0, size=50)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'score': np.concatenate([scores_control, scores_experimental]),\n",
    "    'group': np.repeat(['control', 'experimental'], 50)\n",
    "})\n",
    "\n",
    "control_scores = data.loc[data['group'] == 'control', 'score']\n",
    "experimental_scores = data.loc[data['group'] == 'experimental', 'score']\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print('t-statistic:', t_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(data['score'], data['group'])\n",
    "\n",
    "print('Tukey HSD results:')\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b6158-ee9a-45b1-a677-7d7c0478b7b7",
   "metadata": {},
   "source": [
    "#### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37cf940e-290d-4325-976b-098e64c162dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "==================================\n",
      "    F Value  Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "day  0.9531 29.0000 58.0000 0.5446\n",
      "==================================\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      "group1 group2  meandiff p-adj    lower     upper   reject\n",
      "---------------------------------------------------------\n",
      "     A      B -315.4651 0.5205 -1003.2059 372.2758  False\n",
      "     A      C  178.1571 0.8108  -509.5838 865.8979  False\n",
      "     B      C  493.6221 0.2067  -194.1187 1181.363  False\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "np.random.seed(1234)\n",
    "sales_a = np.random.normal(loc=5000.0, scale=1000.0, size=30)\n",
    "sales_b = np.random.normal(loc=5500.0, scale=1000.0, size=30)\n",
    "sales_c = np.random.normal(loc=6000.0, scale=1000.0, size=30)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'sales': np.concatenate([sales_a, sales_b, sales_c]),\n",
    "    'day': np.repeat(np.arange(1, 31), 3),\n",
    "    'store': np.tile(['A', 'B', 'C'], 30)\n",
    "})\n",
    "\n",
    "model = AnovaRM(data, 'sales', 'store', within=['day'])\n",
    "results = model.fit()\n",
    "\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(data['sales'], data['store'])\n",
    "\n",
    "\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cb73a-5a6c-47a8-bda1-3b289e6d1df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
